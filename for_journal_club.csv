search_keyword, article_name, author, summary, url_link, Number_of_citations 
deep learning in neural networks,Deep learning in neural networks: An overview,J Schmidhuber,In recent years deep artificial neural networks including recurrent ones have won numerous contests in pattern recognition and machine learning This historical survey compactly summarizes relevant work much of it from the previous millennium Shallow and ,https://arxiv.org/pdf/1404.7828,7705
deep learning in neural networks,Neural networks and deep learning,MA Nielsen,Neural networks are one of the most beautiful programming paradigms ever invented In the conventional approach to programming we tell the computer what to do breaking big problems up into many small precisely defined tasks that the computer can easily perform ,https://www.academia.edu/download/58251403/neural_networks_and_deep_learning.pdf,1684
deep learning in neural networks,The vanishing gradient problem during learning recurrent neural nets and problem solutions,S Hochreiter, Because of this property recurrent nets are used in time series prediction and process control 21 December 2016 Multitask Learning for Text Classification with Deep Neural Networks Hossein Ghodrati Noushahr and Samad Ahmadi 5 November 2016 ,http://www.bioinf.jku.at/publications/older/2304.pdf,804
deep learning in neural networks,New types of deep neural network learning for speech recognition and related applications: An overview,L Deng,In this paper we provide an overview of the invited and contributed papers presented at the special session at ICASSP 2013 entitled New Types of Deep Neural Network Learning for Speech Recognition and Related Applications as organized by the authors We also ,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.368.1123&rep=rep1&type=pdf,669
deep learning in neural networks,Phase recovery and holographic image reconstruction using deep learning in neural networks,Y Rivenson,Phase recovery from intensity only measurements forms the heart of coherent imaging techniques and holography In this study we demonstrate that a neural network can learn to perform phase recovery and holographic image reconstruction after appropriate training ,https://www.nature.com/articles/lsa2017141,195
deep learning in neural networks,On optimization methods for deep learning,QV Le, 14 Hinton GE and Salakhutdinov RR Reducing the dimensionality of data with neural networks Science 2006 15 Geoffrey E Hinton Simon Osindero Yee Whye Teh A fast learning algorithm for deep belief nets Neural Computation v 18 n 7 p 1527 1554 July 2006 ,https://openreview.net/pdf?id=Sk4lD3W_bB,784
deep learning in neural networks,Exact solutions to the nonlinear dynamics of learning in deep linear neural networks,AM Saxe,Despite the widespread practical success of deep learning methods our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse We attempt to bridge the gap between the theory and practice of deep learning by ,https://arxiv.org/pdf/1312.6120,716
deep learning in neural networks,Learning to rank short text pairs with convolutional deep neural networks,A Severyn,Learning a similarity function between pairs of objects is at the core of learning to rank approaches In information retrieval tasks we typically deal with query document pairs in question answering question answer pairs However before learning can take place such ,http://eecs.csuohio.edu/~sschung/CIS660/RankShortTextCNNACM2015.pdf,488
deep learning in neural networks,An overview of multi-task learning in deep neural networks,S Ruder,Multi task learning MTL has led to successes in many applications of machine learning from natural language processing and speech recognition to computer vision and drug discovery This article aims to give a general overview of MTL particularly in deep neural ,https://arxiv.org/pdf/1706.05098,503
deep learning in neural networks,Deep sparse rectifier neural networks,X Glorot, Without additional regulariza tion such as an L1 penalty ordinary feedforward neural nets do not have this property The most commonly used activation func tions in the deep learning and neural networks lit erature are the standard logistic sigmoid and the Page 3 ,http://www.jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf,4117
deep learning in neural networks,Neural networks and deep learning,MA Nielsen,Neural networks are one of the most beautiful programming paradigms ever invented In the conventional approach to programming we tell the computer what to do breaking big problems up into many small precisely defined tasks that the computer can easily perform ,https://www.academia.edu/download/58251403/neural_networks_and_deep_learning.pdf,1684
deep learning in neural networks,The vanishing gradient problem during learning recurrent neural nets and problem solutions,S Hochreiter, Because of this property recurrent nets are used in time series prediction and process control 21 December 2016 Multitask Learning for Text Classification with Deep Neural Networks Hossein Ghodrati Noushahr and Samad Ahmadi 5 November 2016 ,http://www.bioinf.jku.at/publications/older/2304.pdf,804
deep learning in neural networks,New types of deep neural network learning for speech recognition and related applications: An overview,L Deng,In this paper we provide an overview of the invited and contributed papers presented at the special session at ICASSP 2013 entitled New Types of Deep Neural Network Learning for Speech Recognition and Related Applications as organized by the authors We also ,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.368.1123&rep=rep1&type=pdf,669
deep learning in neural networks,Phase recovery and holographic image reconstruction using deep learning in neural networks,Y Rivenson,Phase recovery from intensity only measurements forms the heart of coherent imaging techniques and holography In this study we demonstrate that a neural network can learn to perform phase recovery and holographic image reconstruction after appropriate training ,https://www.nature.com/articles/lsa2017141,195
deep learning in neural networks,On optimization methods for deep learning,QV Le, 14 Hinton GE and Salakhutdinov RR Reducing the dimensionality of data with neural networks Science 2006 15 Geoffrey E Hinton Simon Osindero Yee Whye Teh A fast learning algorithm for deep belief nets Neural Computation v 18 n 7 p 1527 1554 July 2006 ,https://openreview.net/pdf?id=Sk4lD3W_bB,784
deep learning in neural networks,Exact solutions to the nonlinear dynamics of learning in deep linear neural networks,AM Saxe,Despite the widespread practical success of deep learning methods our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse We attempt to bridge the gap between the theory and practice of deep learning by ,https://arxiv.org/pdf/1312.6120,716
deep learning in neural networks,Learning to rank short text pairs with convolutional deep neural networks,A Severyn,Learning a similarity function between pairs of objects is at the core of learning to rank approaches In information retrieval tasks we typically deal with query document pairs in question answering question answer pairs However before learning can take place such ,http://eecs.csuohio.edu/~sschung/CIS660/RankShortTextCNNACM2015.pdf,488
deep learning in neural networks,An overview of multi-task learning in deep neural networks,S Ruder,Multi task learning MTL has led to successes in many applications of machine learning from natural language processing and speech recognition to computer vision and drug discovery This article aims to give a general overview of MTL particularly in deep neural ,https://arxiv.org/pdf/1706.05098,503
deep learning in neural networks,Deep sparse rectifier neural networks,X Glorot, Without additional regulariza tion such as an L1 penalty ordinary feedforward neural nets do not have this property The most commonly used activation func tions in the deep learning and neural networks lit erature are the standard logistic sigmoid and the Page 3 ,http://www.jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf,4117
deep learning in neural networks,Deep learning‐based crack damage detection using convolutional neural networks,YJ Cha,A number of image processing techniques IPTs have been implemented for detecting civil infrastructure defects to partially replace human conducted onsite inspections These IPTs are primarily used to manipulate images to extract defect features such as cracks in ,https://www.researchgate.net/profile/Young-Jin_Cha/publication/315613676_Deep_Learning-Based_Crack_Damage_Detection_Using_Convolutional_Neural_Networks/links/59c94bf90f7e9bbfdc32ea61/Deep-Learning-Based-Crack-Damage-Detection-Using-Convolutional-Neural-Networks.pdf,507
deep learning in neural networks,The vanishing gradient problem during learning recurrent neural nets and problem solutions,S Hochreiter, Because of this property recurrent nets are used in time series prediction and process control 21 December 2016 Multitask Learning for Text Classification with Deep Neural Networks Hossein Ghodrati Noushahr and Samad Ahmadi 5 November 2016 ,http://www.bioinf.jku.at/publications/older/2304.pdf,804
deep learning in neural networks,New types of deep neural network learning for speech recognition and related applications: An overview,L Deng,In this paper we provide an overview of the invited and contributed papers presented at the special session at ICASSP 2013 entitled New Types of Deep Neural Network Learning for Speech Recognition and Related Applications as organized by the authors We also ,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.368.1123&rep=rep1&type=pdf,669
deep learning in neural networks,Phase recovery and holographic image reconstruction using deep learning in neural networks,Y Rivenson,Phase recovery from intensity only measurements forms the heart of coherent imaging techniques and holography In this study we demonstrate that a neural network can learn to perform phase recovery and holographic image reconstruction after appropriate training ,https://www.nature.com/articles/lsa2017141,195
deep learning in neural networks,On optimization methods for deep learning,QV Le, 14 Hinton GE and Salakhutdinov RR Reducing the dimensionality of data with neural networks Science 2006 15 Geoffrey E Hinton Simon Osindero Yee Whye Teh A fast learning algorithm for deep belief nets Neural Computation v 18 n 7 p 1527 1554 July 2006 ,https://openreview.net/pdf?id=Sk4lD3W_bB,784
deep learning in neural networks,Exact solutions to the nonlinear dynamics of learning in deep linear neural networks,AM Saxe,Despite the widespread practical success of deep learning methods our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse We attempt to bridge the gap between the theory and practice of deep learning by ,https://arxiv.org/pdf/1312.6120,716
deep learning in neural networks,Learning to rank short text pairs with convolutional deep neural networks,A Severyn,Learning a similarity function between pairs of objects is at the core of learning to rank approaches In information retrieval tasks we typically deal with query document pairs in question answering question answer pairs However before learning can take place such ,http://eecs.csuohio.edu/~sschung/CIS660/RankShortTextCNNACM2015.pdf,488
deep learning in neural networks,An overview of multi-task learning in deep neural networks,S Ruder,Multi task learning MTL has led to successes in many applications of machine learning from natural language processing and speech recognition to computer vision and drug discovery This article aims to give a general overview of MTL particularly in deep neural ,https://arxiv.org/pdf/1706.05098,503
deep learning in neural networks,Deep sparse rectifier neural networks,X Glorot, Without additional regulariza tion such as an L1 penalty ordinary feedforward neural nets do not have this property The most commonly used activation func tions in the deep learning and neural networks lit erature are the standard logistic sigmoid and the Page 3 ,http://www.jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf,4117
deep learning in neural networks,Deep learning‐based crack damage detection using convolutional neural networks,YJ Cha,A number of image processing techniques IPTs have been implemented for detecting civil infrastructure defects to partially replace human conducted onsite inspections These IPTs are primarily used to manipulate images to extract defect features such as cracks in ,https://www.researchgate.net/profile/Young-Jin_Cha/publication/315613676_Deep_Learning-Based_Crack_Damage_Detection_Using_Convolutional_Neural_Networks/links/59c94bf90f7e9bbfdc32ea61/Deep-Learning-Based-Crack-Damage-Detection-Using-Convolutional-Neural-Networks.pdf,507
deep learning in neural networks,Matconvnet: Convolutional neural networks for matlab,A Vedaldi, The goal is to ensure that MatConvNet will stay current for the next several years of research in deep learning Acknowledgments CoRR 2015 4 A Krizhevsky I Sutskever and GE Hinton Imagenet classification with deep convolutional neural networks In Proc ,https://arxiv.org/pdf/1412.4564,2413
deep learning in neural networks,New types of deep neural network learning for speech recognition and related applications: An overview,L Deng,In this paper we provide an overview of the invited and contributed papers presented at the special session at ICASSP 2013 entitled New Types of Deep Neural Network Learning for Speech Recognition and Related Applications as organized by the authors We also ,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.368.1123&rep=rep1&type=pdf,669
deep learning in neural networks,Phase recovery and holographic image reconstruction using deep learning in neural networks,Y Rivenson,Phase recovery from intensity only measurements forms the heart of coherent imaging techniques and holography In this study we demonstrate that a neural network can learn to perform phase recovery and holographic image reconstruction after appropriate training ,https://www.nature.com/articles/lsa2017141,195
deep learning in neural networks,On optimization methods for deep learning,QV Le, 14 Hinton GE and Salakhutdinov RR Reducing the dimensionality of data with neural networks Science 2006 15 Geoffrey E Hinton Simon Osindero Yee Whye Teh A fast learning algorithm for deep belief nets Neural Computation v 18 n 7 p 1527 1554 July 2006 ,https://openreview.net/pdf?id=Sk4lD3W_bB,784
deep learning in neural networks,Exact solutions to the nonlinear dynamics of learning in deep linear neural networks,AM Saxe,Despite the widespread practical success of deep learning methods our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse We attempt to bridge the gap between the theory and practice of deep learning by ,https://arxiv.org/pdf/1312.6120,716
deep learning in neural networks,Learning to rank short text pairs with convolutional deep neural networks,A Severyn,Learning a similarity function between pairs of objects is at the core of learning to rank approaches In information retrieval tasks we typically deal with query document pairs in question answering question answer pairs However before learning can take place such ,http://eecs.csuohio.edu/~sschung/CIS660/RankShortTextCNNACM2015.pdf,488
deep learning in neural networks,An overview of multi-task learning in deep neural networks,S Ruder,Multi task learning MTL has led to successes in many applications of machine learning from natural language processing and speech recognition to computer vision and drug discovery This article aims to give a general overview of MTL particularly in deep neural ,https://arxiv.org/pdf/1706.05098,503
deep learning in neural networks,Deep sparse rectifier neural networks,X Glorot, Without additional regulariza tion such as an L1 penalty ordinary feedforward neural nets do not have this property The most commonly used activation func tions in the deep learning and neural networks lit erature are the standard logistic sigmoid and the Page 3 ,http://www.jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf,4117
deep learning in neural networks,Deep learning‐based crack damage detection using convolutional neural networks,YJ Cha,A number of image processing techniques IPTs have been implemented for detecting civil infrastructure defects to partially replace human conducted onsite inspections These IPTs are primarily used to manipulate images to extract defect features such as cracks in ,https://www.researchgate.net/profile/Young-Jin_Cha/publication/315613676_Deep_Learning-Based_Crack_Damage_Detection_Using_Convolutional_Neural_Networks/links/59c94bf90f7e9bbfdc32ea61/Deep-Learning-Based-Crack-Damage-Detection-Using-Convolutional-Neural-Networks.pdf,507
deep learning in neural networks,Matconvnet: Convolutional neural networks for matlab,A Vedaldi, The goal is to ensure that MatConvNet will stay current for the next several years of research in deep learning Acknowledgments CoRR 2015 4 A Krizhevsky I Sutskever and GE Hinton Imagenet classification with deep convolutional neural networks In Proc ,https://arxiv.org/pdf/1412.4564,2413
deep learning in neural networks,Deep feature learning for knee cartilage segmentation using a triplanar convolutional neural network,K Petersen,Segmentation of anatomical structures in medical images is often based on a voxel pixel classification approach Deep learning systems such as convolutional neural networks CNNs can infer a hierarchical representation of images that fosters categorization We ,https://link.springer.com/content/pdf/10.1007/978-3-642-40763-5_31.pdf,397
deep learning in neural networks,Phase recovery and holographic image reconstruction using deep learning in neural networks,Y Rivenson,Phase recovery from intensity only measurements forms the heart of coherent imaging techniques and holography In this study we demonstrate that a neural network can learn to perform phase recovery and holographic image reconstruction after appropriate training ,https://www.nature.com/articles/lsa2017141,195
deep learning in neural networks,On optimization methods for deep learning,QV Le, 14 Hinton GE and Salakhutdinov RR Reducing the dimensionality of data with neural networks Science 2006 15 Geoffrey E Hinton Simon Osindero Yee Whye Teh A fast learning algorithm for deep belief nets Neural Computation v 18 n 7 p 1527 1554 July 2006 ,https://openreview.net/pdf?id=Sk4lD3W_bB,784
deep learning in neural networks,Exact solutions to the nonlinear dynamics of learning in deep linear neural networks,AM Saxe,Despite the widespread practical success of deep learning methods our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse We attempt to bridge the gap between the theory and practice of deep learning by ,https://arxiv.org/pdf/1312.6120,716
deep learning in neural networks,Learning to rank short text pairs with convolutional deep neural networks,A Severyn,Learning a similarity function between pairs of objects is at the core of learning to rank approaches In information retrieval tasks we typically deal with query document pairs in question answering question answer pairs However before learning can take place such ,http://eecs.csuohio.edu/~sschung/CIS660/RankShortTextCNNACM2015.pdf,488
deep learning in neural networks,An overview of multi-task learning in deep neural networks,S Ruder,Multi task learning MTL has led to successes in many applications of machine learning from natural language processing and speech recognition to computer vision and drug discovery This article aims to give a general overview of MTL particularly in deep neural ,https://arxiv.org/pdf/1706.05098,503
deep learning in neural networks,Deep sparse rectifier neural networks,X Glorot, Without additional regulariza tion such as an L1 penalty ordinary feedforward neural nets do not have this property The most commonly used activation func tions in the deep learning and neural networks lit erature are the standard logistic sigmoid and the Page 3 ,http://www.jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf,4117
deep learning in neural networks,Deep learning‐based crack damage detection using convolutional neural networks,YJ Cha,A number of image processing techniques IPTs have been implemented for detecting civil infrastructure defects to partially replace human conducted onsite inspections These IPTs are primarily used to manipulate images to extract defect features such as cracks in ,https://www.researchgate.net/profile/Young-Jin_Cha/publication/315613676_Deep_Learning-Based_Crack_Damage_Detection_Using_Convolutional_Neural_Networks/links/59c94bf90f7e9bbfdc32ea61/Deep-Learning-Based-Crack-Damage-Detection-Using-Convolutional-Neural-Networks.pdf,507
deep learning in neural networks,Matconvnet: Convolutional neural networks for matlab,A Vedaldi, The goal is to ensure that MatConvNet will stay current for the next several years of research in deep learning Acknowledgments CoRR 2015 4 A Krizhevsky I Sutskever and GE Hinton Imagenet classification with deep convolutional neural networks In Proc ,https://arxiv.org/pdf/1412.4564,2413
deep learning in neural networks,Deep feature learning for knee cartilage segmentation using a triplanar convolutional neural network,K Petersen,Segmentation of anatomical structures in medical images is often based on a voxel pixel classification approach Deep learning systems such as convolutional neural networks CNNs can infer a hierarchical representation of images that fosters categorization We ,https://link.springer.com/content/pdf/10.1007/978-3-642-40763-5_31.pdf,397
deep learning in neural networks,Deep supervised learning for hyperspectral data classification through convolutional neural networks,K Makantasis,Spectral observations along the spectrum in many narrow spectral bands through hyperspectral imaging provides valuable information towards material and object recognition which can be consider as a classification task Most of the existing studies and ,http://users.ntua.gr/karank/img/Makantasis_etal_igrass15.pdf,292
